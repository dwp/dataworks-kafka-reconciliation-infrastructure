groups:
- jobs:
  - start-kafka-reconciliation-development
  - start-kafka-reconciliation-qa
  - start-kafka-reconciliation-integration
  - start-kafka-reconciliation-preprod
  - start-kafka-reconciliation-production
  name: kafka-reconciliation
- jobs:
  - update-pipeline
  name: update-pipeline
jobs:
- max_in_flight: 1
  name: start-kafka-reconciliation-development
  plan:
  - in_parallel:
    - put: meta
      resource: meta-development
    - get: dataworks-aws-ingest-consumers
      trigger: false
    - get: aws-internal-compute
      trigger: false
    - get: aws-ingestion
      trigger: false
  - config:
      image_resource:
        source:
          repository: ((dataworks.terraform_repository))
          tag: ((dataworks.terraform_version))
          version: ((dataworks.terraform_version))
        type: docker-image
      inputs:
      - name: aws-ingestion
      outputs:
      - name: terraform-output-ingest
      params:
        AWS_REGION: ((dataworks.aws_region))
        TF_CLI_ARGS_apply: -lock-timeout=300s
        TF_CLI_ARGS_plan: -lock-timeout=300s
        TF_INPUT: false
        TF_VAR_costcode: ((dataworks.costcode))
        TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
        TF_WORKSPACE: default
      platform: linux
      run:
        args:
        - -exc
        - |
          terraform workspace show
          terraform init
          terraform output --json > ../terraform-output-ingest/outputs.json
        dir: aws-ingestion
        path: sh
    task: terraform-output-ingest
  - config:
      image_resource:
        source:
          repository: ((dataworks.terraform_repository))
          tag: ((dataworks.terraform_version))
          version: ((dataworks.terraform_version))
        type: docker-image
      inputs:
      - name: aws-internal-compute
      outputs:
      - name: terraform-output-internal-compute
      params:
        AWS_REGION: ((dataworks.aws_region))
        TF_CLI_ARGS_apply: -lock-timeout=300s
        TF_CLI_ARGS_plan: -lock-timeout=300s
        TF_INPUT: false
        TF_VAR_costcode: ((dataworks.costcode))
        TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
        TF_WORKSPACE: default
      platform: linux
      run:
        args:
        - -exc
        - |
          terraform workspace show
          terraform init
          terraform output --json > ../terraform-output-internal-compute/outputs.json
        dir: aws-internal-compute
        path: sh
    task: terraform-output-internal-compute
  - config:
      image_resource:
        source:
          repository: ((dataworks.terraform_repository))
          tag: ((dataworks.terraform_version))
          version: ((dataworks.terraform_version))
        type: docker-image
      inputs:
      - name: dataworks-aws-ingest-consumers
      outputs:
      - name: terraform-output-ingest-consumers
      params:
        AWS_REGION: ((dataworks.aws_region))
        TF_CLI_ARGS_apply: -lock-timeout=300s
        TF_CLI_ARGS_plan: -lock-timeout=300s
        TF_INPUT: false
        TF_VAR_costcode: ((dataworks.costcode))
        TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
        TF_WORKSPACE: default
      platform: linux
      run:
        args:
        - -exc
        - |
          terraform workspace show
          terraform init
          terraform output --json > ../terraform-output-ingest-consumers/outputs.json
        dir: dataworks-aws-ingest-consumers
        path: sh
    task: terraform-output-ingest-consumers
  - config:
      image_resource:
        source:
          repository: ((dataworks.docker_awscli_repository))
          version: ((dataworks.docker_awscli_version))
        type: docker-image
      inputs:
      - name: meta
      - name: terraform-output-ingest-consumers
      - name: terraform-output-internal-compute
      - name: terraform-output-ingest
      params:
        ASSUME_DURATION: 14400
        AWS_DEFAULT_REGION: ((dataworks.aws_region))
        AWS_REGION: ((dataworks.aws_region))
        AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
        TIMEOUT: 900
      platform: linux
      run:
        args:
        - -exc
        - |
          source /assume-role
          pipeline_name=`cat "meta/build_pipeline_name"`
          job_name=`cat "meta/build_job_name"`
          build_number=`cat "meta/build_name"`
          build_number_safe=`echo ${build_number/./-}`
          export MANIFEST_MISSING_IMPORTS_TABLE_NAME="$(cat terraform-output-ingest-consumers/outputs.json | jq -r '.manifest_etl.value.table_name_missing_imports_parquet')"
          export MANIFEST_MISSING_EXPORTS_TABLE_NAME="$(cat terraform-output-ingest-consumers/outputs.json | jq -r '.manifest_etl.value.table_name_missing_exports_parquet')"
          export MANIFEST_COUNTS_TABLE_NAME="$(cat terraform-output-ingest-consumers/outputs.json | jq -r '.manifest_etl.value.table_name_counts_parquet')"
          export MANIFEST_MISMATCHED_TIMESTAMPS_TABLE_NAME="$(cat terraform-output-ingest-consumers/outputs.json | jq -r '.manifest_etl.value.table_name_mismatched_timestamps_parquet')"
          export MANIFEST_REPORT_COUNT_OF_IDS="10"
          export MANIFEST_S3_PREFIX="$(cat terraform-output-ingest/outputs.json | jq -r '.manifest_comparison_parameters.value.query_output_s3_prefix')"
          export MANIFEST_S3_BUCKET="$(cat terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')"
          job_id=$(aws batch submit-job --job-queue kafka-reconciliation --job-definition kafka-reconciliation --job-name ${pipeline_name}_${job_name}_${build_number_safe} --parameters manifest_missing_imports_table_name="\"${MANIFEST_MISSING_IMPORTS_TABLE_NAME}\"",manifest_missing_exports_table_name="\"${MANIFEST_MISSING_EXPORTS_TABLE_NAME}\"",manifest_counts_table_name="\"${MANIFEST_COUNTS_TABLE_NAME}\"",manifest_mismatched_timestamps_table_name="\"${MANIFEST_MISMATCHED_TIMESTAMPS_TABLE_NAME}\"",manifest_report_count_of_ids="\"${MANIFEST_REPORT_COUNT_OF_IDS}\"",manifest_s3_prefix="\"${MANIFEST_S3_PREFIX}_streaming_all_incremental\"",manifest_s3_bucket="\"${MANIFEST_S3_BUCKET}\"" | jq -e --raw-output .jobId)
          set +x
          if [[ -z $job_id ]]; then
            echo "Error submitting job, empty job_id received"
            exit 1
          fi
          i=0
          while [[ ${i} -le ${TIMEOUT} ]]
          do
            status=$(aws batch describe-jobs --jobs ${job_id} | jq -e --raw-output '.jobs[0].status')
            case $status in
              FAILED)
                echo "job failed"
                exit 1
                ;;
              SUCCEEDED)
                echo "job succeeded"
                exit 0
                ;;
              SUBMITTED)
                echo "job is currently ${status}"
                ;;
              PENDING)
                echo "job is currently ${status}"
                ;;
              RUNNABLE)
                echo "job is currently ${status}"
                ;;
              STARTING)
                echo "job is currently ${status}"
                ;;
              RUNNING)
                echo "job is currently ${status}"
                ;;
              *)
                echo "unkwnown status $status"
                exit 1
                ;;
            esac
            i=$((i+1))
            sleep 60
          done
          exit 1
        path: sh
    task: kafka-reconciliation
- max_in_flight: 1
  name: start-kafka-reconciliation-qa
  plan:
  - in_parallel:
    - put: meta
      resource: meta-qa
    - get: dataworks-aws-ingest-consumers
      trigger: false
    - get: aws-internal-compute
      trigger: false
    - get: aws-ingestion
      trigger: false
  - config:
      image_resource:
        source:
          repository: ((dataworks.terraform_repository))
          tag: ((dataworks.terraform_version))
          version: ((dataworks.terraform_version))
        type: docker-image
      inputs:
      - name: aws-ingestion
      outputs:
      - name: terraform-output-ingest
      params:
        AWS_REGION: ((dataworks.aws_region))
        TF_CLI_ARGS_apply: -lock-timeout=300s
        TF_CLI_ARGS_plan: -lock-timeout=300s
        TF_INPUT: false
        TF_VAR_costcode: ((dataworks.costcode))
        TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
        TF_WORKSPACE: qa
      platform: linux
      run:
        args:
        - -exc
        - |
          terraform workspace show
          terraform init
          terraform output --json > ../terraform-output-ingest/outputs.json
        dir: aws-ingestion
        path: sh
    task: terraform-output-ingest
  - config:
      image_resource:
        source:
          repository: ((dataworks.terraform_repository))
          tag: ((dataworks.terraform_version))
          version: ((dataworks.terraform_version))
        type: docker-image
      inputs:
      - name: aws-internal-compute
      outputs:
      - name: terraform-output-internal-compute
      params:
        AWS_REGION: ((dataworks.aws_region))
        TF_CLI_ARGS_apply: -lock-timeout=300s
        TF_CLI_ARGS_plan: -lock-timeout=300s
        TF_INPUT: false
        TF_VAR_costcode: ((dataworks.costcode))
        TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
        TF_WORKSPACE: qa
      platform: linux
      run:
        args:
        - -exc
        - |
          terraform workspace show
          terraform init
          terraform output --json > ../terraform-output-internal-compute/outputs.json
        dir: aws-internal-compute
        path: sh
    task: terraform-output-internal-compute
  - config:
      image_resource:
        source:
          repository: ((dataworks.terraform_repository))
          tag: ((dataworks.terraform_version))
          version: ((dataworks.terraform_version))
        type: docker-image
      inputs:
      - name: dataworks-aws-ingest-consumers
      outputs:
      - name: terraform-output-ingest-consumers
      params:
        AWS_REGION: ((dataworks.aws_region))
        TF_CLI_ARGS_apply: -lock-timeout=300s
        TF_CLI_ARGS_plan: -lock-timeout=300s
        TF_INPUT: false
        TF_VAR_costcode: ((dataworks.costcode))
        TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
        TF_WORKSPACE: qa
      platform: linux
      run:
        args:
        - -exc
        - |
          terraform workspace show
          terraform init
          terraform output --json > ../terraform-output-ingest-consumers/outputs.json
        dir: dataworks-aws-ingest-consumers
        path: sh
    task: terraform-output-ingest-consumers
  - config:
      image_resource:
        source:
          repository: ((dataworks.docker_awscli_repository))
          version: ((dataworks.docker_awscli_version))
        type: docker-image
      inputs:
      - name: meta
      - name: terraform-output-ingest-consumers
      - name: terraform-output-internal-compute
      - name: terraform-output-ingest
      params:
        ASSUME_DURATION: 14400
        AWS_DEFAULT_REGION: ((dataworks.aws_region))
        AWS_REGION: ((dataworks.aws_region))
        AWS_ROLE_ARN: arn:aws:iam::((aws_account.qa)):role/ci
        TIMEOUT: 900
      platform: linux
      run:
        args:
        - -exc
        - |
          source /assume-role
          pipeline_name=`cat "meta/build_pipeline_name"`
          job_name=`cat "meta/build_job_name"`
          build_number=`cat "meta/build_name"`
          build_number_safe=`echo ${build_number/./-}`
          export MANIFEST_MISSING_IMPORTS_TABLE_NAME="$(cat terraform-output-ingest-consumers/outputs.json | jq -r '.manifest_etl.value.table_name_missing_imports_parquet')"
          export MANIFEST_MISSING_EXPORTS_TABLE_NAME="$(cat terraform-output-ingest-consumers/outputs.json | jq -r '.manifest_etl.value.table_name_missing_exports_parquet')"
          export MANIFEST_COUNTS_TABLE_NAME="$(cat terraform-output-ingest-consumers/outputs.json | jq -r '.manifest_etl.value.table_name_counts_parquet')"
          export MANIFEST_MISMATCHED_TIMESTAMPS_TABLE_NAME="$(cat terraform-output-ingest-consumers/outputs.json | jq -r '.manifest_etl.value.table_name_mismatched_timestamps_parquet')"
          export MANIFEST_REPORT_COUNT_OF_IDS="10"
          export MANIFEST_S3_PREFIX="$(cat terraform-output-ingest/outputs.json | jq -r '.manifest_comparison_parameters.value.query_output_s3_prefix')"
          export MANIFEST_S3_BUCKET="$(cat terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')"
          job_id=$(aws batch submit-job --job-queue kafka-reconciliation --job-definition kafka-reconciliation --job-name ${pipeline_name}_${job_name}_${build_number_safe} --parameters manifest_missing_imports_table_name="\"${MANIFEST_MISSING_IMPORTS_TABLE_NAME}\"",manifest_missing_exports_table_name="\"${MANIFEST_MISSING_EXPORTS_TABLE_NAME}\"",manifest_counts_table_name="\"${MANIFEST_COUNTS_TABLE_NAME}\"",manifest_mismatched_timestamps_table_name="\"${MANIFEST_MISMATCHED_TIMESTAMPS_TABLE_NAME}\"",manifest_report_count_of_ids="\"${MANIFEST_REPORT_COUNT_OF_IDS}\"",manifest_s3_prefix="\"${MANIFEST_S3_PREFIX}_streaming_all_incremental\"",manifest_s3_bucket="\"${MANIFEST_S3_BUCKET}\"" | jq -e --raw-output .jobId)
          set +x
          if [[ -z $job_id ]]; then
            echo "Error submitting job, empty job_id received"
            exit 1
          fi
          i=0
          while [[ ${i} -le ${TIMEOUT} ]]
          do
            status=$(aws batch describe-jobs --jobs ${job_id} | jq -e --raw-output '.jobs[0].status')
            case $status in
              FAILED)
                echo "job failed"
                exit 1
                ;;
              SUCCEEDED)
                echo "job succeeded"
                exit 0
                ;;
              SUBMITTED)
                echo "job is currently ${status}"
                ;;
              PENDING)
                echo "job is currently ${status}"
                ;;
              RUNNABLE)
                echo "job is currently ${status}"
                ;;
              STARTING)
                echo "job is currently ${status}"
                ;;
              RUNNING)
                echo "job is currently ${status}"
                ;;
              *)
                echo "unkwnown status $status"
                exit 1
                ;;
            esac
            i=$((i+1))
            sleep 60
          done
          exit 1
        path: sh
    task: kafka-reconciliation
- max_in_flight: 1
  name: start-kafka-reconciliation-integration
  plan:
  - in_parallel:
    - put: meta
      resource: meta-integration
    - get: dataworks-aws-ingest-consumers
      trigger: false
    - get: aws-internal-compute
      trigger: false
    - get: aws-ingestion
      trigger: false
  - config:
      image_resource:
        source:
          repository: ((dataworks.terraform_repository))
          tag: ((dataworks.terraform_version))
          version: ((dataworks.terraform_version))
        type: docker-image
      inputs:
      - name: aws-ingestion
      outputs:
      - name: terraform-output-ingest
      params:
        AWS_REGION: ((dataworks.aws_region))
        TF_CLI_ARGS_apply: -lock-timeout=300s
        TF_CLI_ARGS_plan: -lock-timeout=300s
        TF_INPUT: false
        TF_VAR_costcode: ((dataworks.costcode))
        TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
        TF_WORKSPACE: integration
      platform: linux
      run:
        args:
        - -exc
        - |
          terraform workspace show
          terraform init
          terraform output --json > ../terraform-output-ingest/outputs.json
        dir: aws-ingestion
        path: sh
    task: terraform-output-ingest
  - config:
      image_resource:
        source:
          repository: ((dataworks.terraform_repository))
          tag: ((dataworks.terraform_version))
          version: ((dataworks.terraform_version))
        type: docker-image
      inputs:
      - name: aws-internal-compute
      outputs:
      - name: terraform-output-internal-compute
      params:
        AWS_REGION: ((dataworks.aws_region))
        TF_CLI_ARGS_apply: -lock-timeout=300s
        TF_CLI_ARGS_plan: -lock-timeout=300s
        TF_INPUT: false
        TF_VAR_costcode: ((dataworks.costcode))
        TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
        TF_WORKSPACE: integration
      platform: linux
      run:
        args:
        - -exc
        - |
          terraform workspace show
          terraform init
          terraform output --json > ../terraform-output-internal-compute/outputs.json
        dir: aws-internal-compute
        path: sh
    task: terraform-output-internal-compute
  - config:
      image_resource:
        source:
          repository: ((dataworks.terraform_repository))
          tag: ((dataworks.terraform_version))
          version: ((dataworks.terraform_version))
        type: docker-image
      inputs:
      - name: dataworks-aws-ingest-consumers
      outputs:
      - name: terraform-output-ingest-consumers
      params:
        AWS_REGION: ((dataworks.aws_region))
        TF_CLI_ARGS_apply: -lock-timeout=300s
        TF_CLI_ARGS_plan: -lock-timeout=300s
        TF_INPUT: false
        TF_VAR_costcode: ((dataworks.costcode))
        TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
        TF_WORKSPACE: integration
      platform: linux
      run:
        args:
        - -exc
        - |
          terraform workspace show
          terraform init
          terraform output --json > ../terraform-output-ingest-consumers/outputs.json
        dir: dataworks-aws-ingest-consumers
        path: sh
    task: terraform-output-ingest-consumers
  - config:
      image_resource:
        source:
          repository: ((dataworks.docker_awscli_repository))
          version: ((dataworks.docker_awscli_version))
        type: docker-image
      inputs:
      - name: meta
      - name: terraform-output-ingest-consumers
      - name: terraform-output-internal-compute
      - name: terraform-output-ingest
      params:
        ASSUME_DURATION: 14400
        AWS_DEFAULT_REGION: ((dataworks.aws_region))
        AWS_REGION: ((dataworks.aws_region))
        AWS_ROLE_ARN: arn:aws:iam::((aws_account.integration)):role/ci
        TIMEOUT: 900
      platform: linux
      run:
        args:
        - -exc
        - |
          source /assume-role
          pipeline_name=`cat "meta/build_pipeline_name"`
          job_name=`cat "meta/build_job_name"`
          build_number=`cat "meta/build_name"`
          build_number_safe=`echo ${build_number/./-}`
          export MANIFEST_MISSING_IMPORTS_TABLE_NAME="$(cat terraform-output-ingest-consumers/outputs.json | jq -r '.manifest_etl.value.table_name_missing_imports_parquet')"
          export MANIFEST_MISSING_EXPORTS_TABLE_NAME="$(cat terraform-output-ingest-consumers/outputs.json | jq -r '.manifest_etl.value.table_name_missing_exports_parquet')"
          export MANIFEST_COUNTS_TABLE_NAME="$(cat terraform-output-ingest-consumers/outputs.json | jq -r '.manifest_etl.value.table_name_counts_parquet')"
          export MANIFEST_MISMATCHED_TIMESTAMPS_TABLE_NAME="$(cat terraform-output-ingest-consumers/outputs.json | jq -r '.manifest_etl.value.table_name_mismatched_timestamps_parquet')"
          export MANIFEST_REPORT_COUNT_OF_IDS="10"
          export MANIFEST_S3_PREFIX="$(cat terraform-output-ingest/outputs.json | jq -r '.manifest_comparison_parameters.value.query_output_s3_prefix')"
          export MANIFEST_S3_BUCKET="$(cat terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')"
          job_id=$(aws batch submit-job --job-queue kafka-reconciliation --job-definition kafka-reconciliation --job-name ${pipeline_name}_${job_name}_${build_number_safe} --parameters manifest_missing_imports_table_name="\"${MANIFEST_MISSING_IMPORTS_TABLE_NAME}\"",manifest_missing_exports_table_name="\"${MANIFEST_MISSING_EXPORTS_TABLE_NAME}\"",manifest_counts_table_name="\"${MANIFEST_COUNTS_TABLE_NAME}\"",manifest_mismatched_timestamps_table_name="\"${MANIFEST_MISMATCHED_TIMESTAMPS_TABLE_NAME}\"",manifest_report_count_of_ids="\"${MANIFEST_REPORT_COUNT_OF_IDS}\"",manifest_s3_prefix="\"${MANIFEST_S3_PREFIX}_streaming_all_incremental\"",manifest_s3_bucket="\"${MANIFEST_S3_BUCKET}\"" | jq -e --raw-output .jobId)
          set +x
          if [[ -z $job_id ]]; then
            echo "Error submitting job, empty job_id received"
            exit 1
          fi
          i=0
          while [[ ${i} -le ${TIMEOUT} ]]
          do
            status=$(aws batch describe-jobs --jobs ${job_id} | jq -e --raw-output '.jobs[0].status')
            case $status in
              FAILED)
                echo "job failed"
                exit 1
                ;;
              SUCCEEDED)
                echo "job succeeded"
                exit 0
                ;;
              SUBMITTED)
                echo "job is currently ${status}"
                ;;
              PENDING)
                echo "job is currently ${status}"
                ;;
              RUNNABLE)
                echo "job is currently ${status}"
                ;;
              STARTING)
                echo "job is currently ${status}"
                ;;
              RUNNING)
                echo "job is currently ${status}"
                ;;
              *)
                echo "unkwnown status $status"
                exit 1
                ;;
            esac
            i=$((i+1))
            sleep 60
          done
          exit 1
        path: sh
    task: kafka-reconciliation
- max_in_flight: 1
  name: start-kafka-reconciliation-preprod
  plan:
  - in_parallel:
    - put: meta
      resource: meta-preprod
    - get: dataworks-aws-ingest-consumers
      trigger: false
    - get: aws-internal-compute
      trigger: false
    - get: aws-ingestion
      trigger: false
  - config:
      image_resource:
        source:
          repository: ((dataworks.terraform_repository))
          tag: ((dataworks.terraform_version))
          version: ((dataworks.terraform_version))
        type: docker-image
      inputs:
      - name: aws-ingestion
      outputs:
      - name: terraform-output-ingest
      params:
        AWS_REGION: ((dataworks.aws_region))
        TF_CLI_ARGS_apply: -lock-timeout=300s
        TF_CLI_ARGS_plan: -lock-timeout=300s
        TF_INPUT: false
        TF_VAR_costcode: ((dataworks.costcode))
        TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
        TF_WORKSPACE: preprod
      platform: linux
      run:
        args:
        - -exc
        - |
          terraform workspace show
          terraform init
          terraform output --json > ../terraform-output-ingest/outputs.json
        dir: aws-ingestion
        path: sh
    task: terraform-output-ingest
  - config:
      image_resource:
        source:
          repository: ((dataworks.terraform_repository))
          tag: ((dataworks.terraform_version))
          version: ((dataworks.terraform_version))
        type: docker-image
      inputs:
      - name: aws-internal-compute
      outputs:
      - name: terraform-output-internal-compute
      params:
        AWS_REGION: ((dataworks.aws_region))
        TF_CLI_ARGS_apply: -lock-timeout=300s
        TF_CLI_ARGS_plan: -lock-timeout=300s
        TF_INPUT: false
        TF_VAR_costcode: ((dataworks.costcode))
        TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
        TF_WORKSPACE: preprod
      platform: linux
      run:
        args:
        - -exc
        - |
          terraform workspace show
          terraform init
          terraform output --json > ../terraform-output-internal-compute/outputs.json
        dir: aws-internal-compute
        path: sh
    task: terraform-output-internal-compute
  - config:
      image_resource:
        source:
          repository: ((dataworks.terraform_repository))
          tag: ((dataworks.terraform_version))
          version: ((dataworks.terraform_version))
        type: docker-image
      inputs:
      - name: dataworks-aws-ingest-consumers
      outputs:
      - name: terraform-output-ingest-consumers
      params:
        AWS_REGION: ((dataworks.aws_region))
        TF_CLI_ARGS_apply: -lock-timeout=300s
        TF_CLI_ARGS_plan: -lock-timeout=300s
        TF_INPUT: false
        TF_VAR_costcode: ((dataworks.costcode))
        TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
        TF_WORKSPACE: preprod
      platform: linux
      run:
        args:
        - -exc
        - |
          terraform workspace show
          terraform init
          terraform output --json > ../terraform-output-ingest-consumers/outputs.json
        dir: dataworks-aws-ingest-consumers
        path: sh
    task: terraform-output-ingest-consumers
  - config:
      image_resource:
        source:
          repository: ((dataworks.docker_awscli_repository))
          version: ((dataworks.docker_awscli_version))
        type: docker-image
      inputs:
      - name: meta
      - name: terraform-output-ingest-consumers
      - name: terraform-output-internal-compute
      - name: terraform-output-ingest
      params:
        ASSUME_DURATION: 14400
        AWS_DEFAULT_REGION: ((dataworks.aws_region))
        AWS_REGION: ((dataworks.aws_region))
        AWS_ROLE_ARN: arn:aws:iam::((aws_account.preprod)):role/ci
        TIMEOUT: 900
      platform: linux
      run:
        args:
        - -exc
        - |
          source /assume-role
          pipeline_name=`cat "meta/build_pipeline_name"`
          job_name=`cat "meta/build_job_name"`
          build_number=`cat "meta/build_name"`
          build_number_safe=`echo ${build_number/./-}`
          export MANIFEST_MISSING_IMPORTS_TABLE_NAME="$(cat terraform-output-ingest-consumers/outputs.json | jq -r '.manifest_etl.value.table_name_missing_imports_parquet')"
          export MANIFEST_MISSING_EXPORTS_TABLE_NAME="$(cat terraform-output-ingest-consumers/outputs.json | jq -r '.manifest_etl.value.table_name_missing_exports_parquet')"
          export MANIFEST_COUNTS_TABLE_NAME="$(cat terraform-output-ingest-consumers/outputs.json | jq -r '.manifest_etl.value.table_name_counts_parquet')"
          export MANIFEST_MISMATCHED_TIMESTAMPS_TABLE_NAME="$(cat terraform-output-ingest-consumers/outputs.json | jq -r '.manifest_etl.value.table_name_mismatched_timestamps_parquet')"
          export MANIFEST_REPORT_COUNT_OF_IDS="10"
          export MANIFEST_S3_PREFIX="$(cat terraform-output-ingest/outputs.json | jq -r '.manifest_comparison_parameters.value.query_output_s3_prefix')"
          export MANIFEST_S3_BUCKET="$(cat terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')"
          job_id=$(aws batch submit-job --job-queue kafka-reconciliation --job-definition kafka-reconciliation --job-name ${pipeline_name}_${job_name}_${build_number_safe} --parameters manifest_missing_imports_table_name="\"${MANIFEST_MISSING_IMPORTS_TABLE_NAME}\"",manifest_missing_exports_table_name="\"${MANIFEST_MISSING_EXPORTS_TABLE_NAME}\"",manifest_counts_table_name="\"${MANIFEST_COUNTS_TABLE_NAME}\"",manifest_mismatched_timestamps_table_name="\"${MANIFEST_MISMATCHED_TIMESTAMPS_TABLE_NAME}\"",manifest_report_count_of_ids="\"${MANIFEST_REPORT_COUNT_OF_IDS}\"",manifest_s3_prefix="\"${MANIFEST_S3_PREFIX}_streaming_all_incremental\"",manifest_s3_bucket="\"${MANIFEST_S3_BUCKET}\"" | jq -e --raw-output .jobId)
          set +x
          if [[ -z $job_id ]]; then
            echo "Error submitting job, empty job_id received"
            exit 1
          fi
          i=0
          while [[ ${i} -le ${TIMEOUT} ]]
          do
            status=$(aws batch describe-jobs --jobs ${job_id} | jq -e --raw-output '.jobs[0].status')
            case $status in
              FAILED)
                echo "job failed"
                exit 1
                ;;
              SUCCEEDED)
                echo "job succeeded"
                exit 0
                ;;
              SUBMITTED)
                echo "job is currently ${status}"
                ;;
              PENDING)
                echo "job is currently ${status}"
                ;;
              RUNNABLE)
                echo "job is currently ${status}"
                ;;
              STARTING)
                echo "job is currently ${status}"
                ;;
              RUNNING)
                echo "job is currently ${status}"
                ;;
              *)
                echo "unkwnown status $status"
                exit 1
                ;;
            esac
            i=$((i+1))
            sleep 60
          done
          exit 1
        path: sh
    task: kafka-reconciliation
- max_in_flight: 1
  name: start-kafka-reconciliation-production
  plan:
  - in_parallel:
    - put: meta
      resource: meta-production
    - get: dataworks-aws-ingest-consumers
      trigger: false
    - get: aws-internal-compute
      trigger: false
    - get: aws-ingestion
      trigger: false
  - config:
      image_resource:
        source:
          repository: ((dataworks.terraform_repository))
          tag: ((dataworks.terraform_version))
          version: ((dataworks.terraform_version))
        type: docker-image
      inputs:
      - name: aws-ingestion
      outputs:
      - name: terraform-output-ingest
      params:
        AWS_REGION: ((dataworks.aws_region))
        TF_CLI_ARGS_apply: -lock-timeout=300s
        TF_CLI_ARGS_plan: -lock-timeout=300s
        TF_INPUT: false
        TF_VAR_costcode: ((dataworks.costcode))
        TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
        TF_WORKSPACE: production
      platform: linux
      run:
        args:
        - -exc
        - |
          terraform workspace show
          terraform init
          terraform output --json > ../terraform-output-ingest/outputs.json
        dir: aws-ingestion
        path: sh
    task: terraform-output-ingest
  - config:
      image_resource:
        source:
          repository: ((dataworks.terraform_repository))
          tag: ((dataworks.terraform_version))
          version: ((dataworks.terraform_version))
        type: docker-image
      inputs:
      - name: aws-internal-compute
      outputs:
      - name: terraform-output-internal-compute
      params:
        AWS_REGION: ((dataworks.aws_region))
        TF_CLI_ARGS_apply: -lock-timeout=300s
        TF_CLI_ARGS_plan: -lock-timeout=300s
        TF_INPUT: false
        TF_VAR_costcode: ((dataworks.costcode))
        TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
        TF_WORKSPACE: production
      platform: linux
      run:
        args:
        - -exc
        - |
          terraform workspace show
          terraform init
          terraform output --json > ../terraform-output-internal-compute/outputs.json
        dir: aws-internal-compute
        path: sh
    task: terraform-output-internal-compute
  - config:
      image_resource:
        source:
          repository: ((dataworks.terraform_repository))
          tag: ((dataworks.terraform_version))
          version: ((dataworks.terraform_version))
        type: docker-image
      inputs:
      - name: dataworks-aws-ingest-consumers
      outputs:
      - name: terraform-output-ingest-consumers
      params:
        AWS_REGION: ((dataworks.aws_region))
        TF_CLI_ARGS_apply: -lock-timeout=300s
        TF_CLI_ARGS_plan: -lock-timeout=300s
        TF_INPUT: false
        TF_VAR_costcode: ((dataworks.costcode))
        TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
        TF_WORKSPACE: production
      platform: linux
      run:
        args:
        - -exc
        - |
          terraform workspace show
          terraform init
          terraform output --json > ../terraform-output-ingest-consumers/outputs.json
        dir: dataworks-aws-ingest-consumers
        path: sh
    task: terraform-output-ingest-consumers
  - config:
      image_resource:
        source:
          repository: ((dataworks.docker_awscli_repository))
          version: ((dataworks.docker_awscli_version))
        type: docker-image
      inputs:
      - name: meta
      - name: terraform-output-ingest-consumers
      - name: terraform-output-internal-compute
      - name: terraform-output-ingest
      params:
        ASSUME_DURATION: 14400
        AWS_DEFAULT_REGION: ((dataworks.aws_region))
        AWS_REGION: ((dataworks.aws_region))
        AWS_ROLE_ARN: arn:aws:iam::((aws_account.production)):role/ci
        TIMEOUT: 900
      platform: linux
      run:
        args:
        - -exc
        - |
          source /assume-role
          pipeline_name=`cat "meta/build_pipeline_name"`
          job_name=`cat "meta/build_job_name"`
          build_number=`cat "meta/build_name"`
          build_number_safe=`echo ${build_number/./-}`
          export MANIFEST_MISSING_IMPORTS_TABLE_NAME="$(cat terraform-output-ingest-consumers/outputs.json | jq -r '.manifest_etl.value.table_name_missing_imports_parquet')"
          export MANIFEST_MISSING_EXPORTS_TABLE_NAME="$(cat terraform-output-ingest-consumers/outputs.json | jq -r '.manifest_etl.value.table_name_missing_exports_parquet')"
          export MANIFEST_COUNTS_TABLE_NAME="$(cat terraform-output-ingest-consumers/outputs.json | jq -r '.manifest_etl.value.table_name_counts_parquet')"
          export MANIFEST_MISMATCHED_TIMESTAMPS_TABLE_NAME="$(cat terraform-output-ingest-consumers/outputs.json | jq -r '.manifest_etl.value.table_name_mismatched_timestamps_parquet')"
          export MANIFEST_REPORT_COUNT_OF_IDS="10"
          export MANIFEST_S3_PREFIX="$(cat terraform-output-ingest/outputs.json | jq -r '.manifest_comparison_parameters.value.query_output_s3_prefix')"
          export MANIFEST_S3_BUCKET="$(cat terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')"
          job_id=$(aws batch submit-job --job-queue kafka-reconciliation --job-definition kafka-reconciliation --job-name ${pipeline_name}_${job_name}_${build_number_safe} --parameters manifest_missing_imports_table_name="\"${MANIFEST_MISSING_IMPORTS_TABLE_NAME}\"",manifest_missing_exports_table_name="\"${MANIFEST_MISSING_EXPORTS_TABLE_NAME}\"",manifest_counts_table_name="\"${MANIFEST_COUNTS_TABLE_NAME}\"",manifest_mismatched_timestamps_table_name="\"${MANIFEST_MISMATCHED_TIMESTAMPS_TABLE_NAME}\"",manifest_report_count_of_ids="\"${MANIFEST_REPORT_COUNT_OF_IDS}\"",manifest_s3_prefix="\"${MANIFEST_S3_PREFIX}_streaming_all_incremental\"",manifest_s3_bucket="\"${MANIFEST_S3_BUCKET}\"" | jq -e --raw-output .jobId)
          set +x
          if [[ -z $job_id ]]; then
            echo "Error submitting job, empty job_id received"
            exit 1
          fi
          i=0
          while [[ ${i} -le ${TIMEOUT} ]]
          do
            status=$(aws batch describe-jobs --jobs ${job_id} | jq -e --raw-output '.jobs[0].status')
            case $status in
              FAILED)
                echo "job failed"
                exit 1
                ;;
              SUCCEEDED)
                echo "job succeeded"
                exit 0
                ;;
              SUBMITTED)
                echo "job is currently ${status}"
                ;;
              PENDING)
                echo "job is currently ${status}"
                ;;
              RUNNABLE)
                echo "job is currently ${status}"
                ;;
              STARTING)
                echo "job is currently ${status}"
                ;;
              RUNNING)
                echo "job is currently ${status}"
                ;;
              *)
                echo "unkwnown status $status"
                exit 1
                ;;
            esac
            i=$((i+1))
            sleep 60
          done
          exit 1
        path: sh
    task: kafka-reconciliation
- name: update-pipeline
  plan:
  - get: dataworks-kafka-reconciliation-infrastructure
    resource: dataworks-kafka-reconciliation-infrastructure
    trigger: true
  - config:
      image_resource:
        source:
          repository: ((dataworks.docker_aviator_repository))
          version: ((dataworks.docker_aviator_version))
        type: docker-image
      inputs:
      - name: dataworks-kafka-reconciliation-infrastructure
      outputs:
      - name: pipeline
      platform: linux
      run:
        args:
        - -exc
        - |
          sed -i 's/fly/nofly/' aviator-kafka-reconciliation.yml
          /usr/bin/aviator -f aviator-kafka-reconciliation.yml
          mv aviator_pipeline_kafka-reconciliation.yml ../pipeline
        dir: dataworks-kafka-reconciliation-infrastructure
        path: sh
    task: aviator
  - file: pipeline/aviator_pipeline_kafka-reconciliation.yml
    set_pipeline: kafka-reconciliation
resource_types:
- name: meta
  source:
    repository: olhtbr/metadata-resource
    tag: 2.0.1
  type: docker-image
resources:
- check_every: 5m
  name: aws-ingestion
  source:
    api_endpoint: https://((dataworks.enterprise_github_url))/api/v3/
    branch: master
    password: ((dataworks-secrets.enterprise_github_pat))
    uri: https://((dataworks.enterprise_github_url))/dip/aws-ingestion.git
    username: ((dataworks.enterprise_github_username))
  type: git
  webhook_token: ((dataworks.concourse_github_webhook_token))
- check_every: 5m
  name: aws-internal-compute
  source:
    api_endpoint: https://((dataworks.enterprise_github_url))/api/v3/
    branch: master
    ignore_path:
    - ci/*
    - aviator.yml
    - aviator-ingest-emr-manual-tasks.yml
    - aviator-ingest-emr-scheduled-tasks.yml
    - aviator-utility.yml
    password: ((dataworks-secrets.enterprise_github_pat))
    uri: https://((dataworks.enterprise_github_url))/dip/aws-internal-compute.git
    username: ((dataworks.enterprise_github_username))
  type: git
  webhook_token: ((dataworks.concourse_github_webhook_token))
- check_every: 5m
  name: dataworks-aws-ingest-consumers
  source:
    access_token: ((dataworks-secrets.concourse_github_pat))
    branch: master
    uri: https://github.com/dwp/dataworks-aws-ingest-consumers.git
  type: git
  webhook_token: ((dataworks.concourse_github_webhook_token))
- check_every: 5m
  name: dataworks-kafka-reconciliation-infrastructure
  source:
    access_token: ((dataworks-secrets.concourse_github_pat))
    branch: master
    paths:
    - ci/kafka-reconciliation/*
    - aviator-kafka-reconciliation.yml
    uri: https://github.com/dwp/dataworks-kafka-reconciliation-infrastructure.git
  type: git
  webhook_token: ((dataworks.concourse_github_webhook_token))
- name: meta-development
  type: meta
- name: meta-qa
  type: meta
- name: meta-preprod
  type: meta
- name: meta-production
  type: meta
- name: meta-integration
  type: meta
